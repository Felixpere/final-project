{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ea1c6873-7443-42c0-b493-690d2f65baa8",
   "metadata": {},
   "source": [
    "# 01 â€“ Telegram Signal Extraction\n",
    "\n",
    "This notebook is responsible for collecting, parsing, cleaning, and updating cryptocurrency trading signal messages from a Telegram group.\n",
    "\n",
    "It serves as the **data ingestion and preprocessing entry point** for the entire project. The main objectives of this notebook are:\n",
    "\n",
    "## Purpose\n",
    "- Retrieve new messages from a Telegram signals group using the **Telethon** client.\n",
    "- **Parse** each message to extract relevant trading data (symbol, direction, entry price, take-profit targets, profit updates).\n",
    "- **Clean** the parsed data by removing malformed or incomplete entries.\n",
    "- **Append** the newly extracted data to the existing cleaned CSV files.\n",
    "- Maintain a centralized and **up-to-date historical record** of both full trade signals and hit price updates.\n",
    "\n",
    "## Key Features\n",
    "- Loads API credentials from a `.env` file.\n",
    "- Automatically detects and processes only new messages using `offset_date` logic.\n",
    "- Classifies messages into two categories:\n",
    "  - `signal_data`: messages that contain full trade entries with take-profit targets.\n",
    "  - `update_data`: profit updates that report a `hit_price` but no new entry.\n",
    "- Cleans symbols and timestamps.\n",
    "- Exports updated datasets to:\n",
    "  - `data/telegram_signals_clean.csv`\n",
    "  - `data/telegram_updates_clean.csv`\n",
    "- Saves raw message content into a local JSON backup.\n",
    "\n",
    "## Output Files\n",
    "- `raw_messages.json`: Raw text and timestamps from Telegram.\n",
    "- `telegram_signals_clean.csv`: Parsed, deduplicated, and clean trading signals.\n",
    "- `telegram_updates_clean.csv`: Cleaned profit target updates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5560672c-bcba-430e-b8a2-f2277344119f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from dotenv import load_dotenv\n",
    "import re\n",
    "from telethon import TelegramClient\n",
    "\n",
    "# Load credentials from .env\n",
    "load_dotenv()\n",
    "API_ID = int(os.getenv(\"API_ID\"))\n",
    "API_HASH = os.getenv(\"API_HASH\")\n",
    "GROUP_ID = -1001717037581  # Telegram group ID\n",
    "\n",
    "# Define paths\n",
    "signals_csv = Path(\"../data/telegram_signals_clean.csv\")\n",
    "updates_csv = Path(\"../data/telegram_updates_clean.csv\")\n",
    "raw_path = Path(\"../data/raw/raw_messages.json\")\n",
    "\n",
    "# Load existing CSVs\n",
    "existing_signals = pd.read_csv(signals_csv) if signals_csv.exists() else pd.DataFrame()\n",
    "existing_updates = pd.read_csv(updates_csv) if updates_csv.exists() else pd.DataFrame()\n",
    "\n",
    "# Get timestamp of most recent signal/update\n",
    "last_signal_time = pd.to_datetime(existing_signals[\"timestamp\"]).max() if not existing_signals.empty else datetime(2024, 1, 1)\n",
    "last_update_time = pd.to_datetime(existing_updates[\"timestamp\"]).max() if not existing_updates.empty else datetime(2024, 1, 1)\n",
    "\n",
    "# Parse signal from text\n",
    "def parse_signal(text):\n",
    "    result = {}\n",
    "    symbol_match = re.search(r\"#([A-Z0-9]+)[^\\s/]*/USDT\", text)\n",
    "    if symbol_match:\n",
    "        result[\"symbol\"] = symbol_match.group(1) + \"/USDT\"\n",
    "\n",
    "    direction_match = re.search(r\"\\b(Long|Short)\\b\", text, re.IGNORECASE)\n",
    "    if direction_match:\n",
    "        result[\"direction\"] = direction_match.group(1).capitalize()\n",
    "\n",
    "    entry_match = re.search(r\"Entry[^0-9]{0,10}(\\d+\\.\\d+)\", text)\n",
    "    if entry_match:\n",
    "        result[\"entry\"] = float(entry_match.group(1))\n",
    "\n",
    "    tp_matches = re.findall(r\"(\\d+\\.\\d+)\\s*\\((\\d+)% of profit\\)\", text)\n",
    "    for price, percent in tp_matches:\n",
    "        result[f\"tp_{percent}\"] = float(price)\n",
    "\n",
    "    price_hit = re.search(r\"Price[^0-9]{0,10}(\\d+\\.\\d+)\", text)\n",
    "    if price_hit:\n",
    "        result[\"hit_price\"] = float(price_hit.group(1))\n",
    "\n",
    "    return result\n",
    "\n",
    "# Main function\n",
    "async def run_all():\n",
    "    async with TelegramClient(\"session_felix\", API_ID, API_HASH) as client:\n",
    "\n",
    "        # Show the latest message from the group\n",
    "        message = await client.get_messages(GROUP_ID, limit=1)\n",
    "        print(\"Latest message from the group:\\n\")\n",
    "        print(message[0].text)\n",
    "\n",
    "        # Fetch new messages since last update\n",
    "        messages = []\n",
    "        async for msg in client.iter_messages(GROUP_ID, offset_date=min(last_signal_time, last_update_time), reverse=True):\n",
    "            if msg.text:\n",
    "                messages.append({\"text\": msg.text, \"timestamp\": msg.date.isoformat()})\n",
    "\n",
    "        # Save messages to JSON\n",
    "        with open(raw_path, \"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump(messages, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "        # Parse and clean messages\n",
    "        parsed_messages = []\n",
    "        for msg in messages:\n",
    "            parsed = parse_signal(msg[\"text\"])\n",
    "            parsed[\"timestamp\"] = msg[\"timestamp\"]\n",
    "            parsed_messages.append(parsed)\n",
    "\n",
    "        # Classify parsed messages\n",
    "        signal_data = [m for m in parsed_messages if \"entry\" in m and any(k.startswith(\"tp_\") for k in m)]\n",
    "        update_data = [m for m in parsed_messages if \"symbol\" in m and \"entry\" not in m and \"hit_price\" in m]\n",
    "\n",
    "        df_signals = pd.DataFrame(signal_data)\n",
    "        df_updates = pd.DataFrame(update_data)\n",
    "\n",
    "        # Remove incomplete rows\n",
    "        df_signals.dropna(subset=[\"symbol\", \"entry\", \"tp_40\", \"tp_60\", \"tp_80\", \"tp_100\"], inplace=True)\n",
    "        df_updates.dropna(subset=[\"symbol\", \"hit_price\"], inplace=True)\n",
    "\n",
    "        # Clean symbol format\n",
    "        def clean_symbol(s):\n",
    "            if pd.isna(s): return None\n",
    "            return re.sub(r\"[^A-Z0-9/]\", \"\", s).replace(\"/\", \"\")\n",
    "\n",
    "        df_signals[\"symbol\"] = df_signals[\"symbol\"].apply(clean_symbol)\n",
    "        df_updates[\"symbol\"] = df_updates[\"symbol\"].apply(clean_symbol)\n",
    "\n",
    "        # Format timestamps\n",
    "        df_signals[\"timestamp\"] = pd.to_datetime(df_signals[\"timestamp\"])\n",
    "        df_updates[\"timestamp\"] = pd.to_datetime(df_updates[\"timestamp\"])\n",
    "\n",
    "        # Append and deduplicate with existing data\n",
    "        df_signals = pd.concat([existing_signals, df_signals], ignore_index=True).drop_duplicates()\n",
    "        df_updates = pd.concat([existing_updates, df_updates], ignore_index=True).drop_duplicates()\n",
    "\n",
    "        # Export updated CSVs\n",
    "        df_signals.to_csv(signals_csv, index=False)\n",
    "        df_updates.to_csv(updates_csv, index=False)\n",
    "\n",
    "        print(f\"\\nUpdated: {df_signals.shape[0]} signals, {df_updates.shape[0]} updates.\")\n",
    "\n",
    "# Run the function\n",
    "await run_all()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc460454",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "# Load messages from the JSON file\n",
    "raw_path = Path(\"../data/raw/raw_messages.json\")\n",
    "\n",
    "with open(raw_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    raw_messages = json.load(f)\n",
    "\n",
    "print(f\"Messages loaded: {len(raw_messages)}\")\n",
    "print(\"Example:\", raw_messages[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (final_proyect_env)",
   "language": "python",
   "name": "final_proyect_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
