{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5f68102c-59c4-473d-a86c-86bb960a6ea5",
   "metadata": {},
   "source": [
    "# Track and Store Market Prices\n",
    "\n",
    "Signal Tracking and Symbol Frequency Analysis\n",
    "\n",
    "This notebook is part of a broader project that aims to evaluate the reliability and characteristics of cryptocurrency trading signals sent through a Telegram group. Specifically, this notebook focuses on identifying the most active and persistent trading symbols based on historical signal data.\n",
    "\n",
    "## Purpose\n",
    "\n",
    "The main objective of this notebook is to analyze the historical behavior of symbols present in the signal dataset in order to:\n",
    "\n",
    "- Determine the first and last time each symbol was mentioned.\n",
    "- Measure the total number of times each symbol was signaled.\n",
    "- Calculate the number of days each symbol has been \"active\" in the dataset.\n",
    "- Filter out symbols that do not meet basic consistency criteria.\n",
    "- Rank the top symbols by their average signaling frequency per day.\n",
    "\n",
    "These metrics allow us to prioritize symbols that have shown sustained usage over time and filter out low-frequency or short-lived mentions.\n",
    "\n",
    "## Methodology\n",
    "\n",
    "The process followed in this notebook includes the following steps:\n",
    "\n",
    "1. **Data loading and cleaning**:\n",
    "   - The dataset of cleaned trading signals (`telegram_signals_clean.csv`) is loaded.\n",
    "   - Timestamps are parsed and validated.\n",
    "   - Rows with invalid or missing timestamps are removed.\n",
    "\n",
    "2. **Signal aggregation**:\n",
    "   - For each symbol, the following metrics are computed:\n",
    "     - `first_signal_date`\n",
    "     - `last_signal_date`\n",
    "     - `signal_count`\n",
    "   - These values are saved in a separate file for reuse (`symbols_first_seen.csv`).\n",
    "\n",
    "3. **Filtering criteria**:\n",
    "   - Only symbols with at least 180 days between their first and last appearance are retained.\n",
    "   - A minimum of 10 total signals is required for a symbol to be considered.\n",
    "\n",
    "4. **Frequency scoring**:\n",
    "   - For each filtered symbol, we compute `signals_per_day` as a measure of relative intensity.\n",
    "   - The top 20 symbols are selected and saved as `top_20_symbols_by_frequency.csv`.\n",
    "\n",
    "## Outputs\n",
    "\n",
    "This notebook generates two key output files in the `data/clean/` directory:\n",
    "\n",
    "- `symbols_first_seen.csv`: A summary table of all symbols with their activity metrics.\n",
    "- `top_20_symbols_by_frequency.csv`: A list of the most actively used symbols, ranked by normalized frequency.\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "The output of this notebook will be used in the next stage of the project (`04_signal_stats_analysis.ipynb`), where we will focus on deeper exploration of the selected symbols, including:\n",
    "\n",
    "- Distribution of entry prices\n",
    "- Target price patterns (`tp_40`, `tp_50`, etc.)\n",
    "- Volatility and signal timing behavior\n",
    "- Visual exploration of symbol characteristics\n",
    "\n",
    "This separation of concerns ensures that the core statistical summary is reusable and modular for different downstream analyses.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3be1b66d-c858-45be-bb80-31200eccc5da",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#install pybit\n",
    "import sys\n",
    "!{sys.executable} -m pip install pybit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f414e606-97f8-46f9-b46c-c74643327c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load libraries\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import sqlite3\n",
    "from uuid import uuid4\n",
    "from pybit.unified_trading import HTTP\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import pandas as pd\n",
    "import requests\n",
    "import time\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "api_key = os.getenv(\"BYBIT_API_KEY\")\n",
    "api_secret = os.getenv(\"BYBIT_API_SECRET\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "def6b4a7-bac2-490e-98b1-ad9d8eba17b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load signals and compute statistics per symbol\n",
    "import pandas as pd\n",
    "\n",
    "# Load the cleaned signals dataset\n",
    "signals_path = \"../data/clean/telegram_signals_clean.csv\"\n",
    "df_signals = pd.read_csv(signals_path)\n",
    "\n",
    "# Convert 'timestamp' to datetime format (with timezone handling)\n",
    "df_signals[\"timestamp\"] = pd.to_datetime(df_signals[\"timestamp\"], errors=\"coerce\", utc=True)\n",
    "\n",
    "# Drop rows with invalid or missing timestamps (optional safeguard)\n",
    "df_signals = df_signals.dropna(subset=[\"timestamp\"])\n",
    "\n",
    "# Group by symbol and compute first, last, and total signals\n",
    "symbol_stats = df_signals.groupby(\"symbol\").agg(\n",
    "    first_signal_date=(\"timestamp\", \"min\"),\n",
    "    last_signal_date=(\"timestamp\", \"max\"),\n",
    "    signal_count=(\"timestamp\", \"count\")\n",
    ").reset_index()\n",
    "\n",
    "# Sort by first appearance for readability\n",
    "symbol_stats = symbol_stats.sort_values(\"first_signal_date\")\n",
    "\n",
    "# Display the result\n",
    "print(symbol_stats.head(20))  # Or use display(symbol_stats)\n",
    "\n",
    "# Save full stats to CSV\n",
    "symbol_stats.to_csv(\"../data/clean/symbols_first_seen.csv\", index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75b48123-1009-4045-90cb-ca1459617cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Load all signals\n",
    "signals_path = \"../data/clean/telegram_signals_clean.csv\"\n",
    "df_signals = pd.read_csv(signals_path)\n",
    "df_signals[\"timestamp\"] = pd.to_datetime(df_signals[\"timestamp\"], utc=True, errors=\"coerce\")\n",
    "\n",
    "# Filter last 6 months\n",
    "six_months_ago = pd.Timestamp.utcnow() - pd.Timedelta(days=180)\n",
    "recent_signals = df_signals[df_signals[\"timestamp\"] >= six_months_ago]\n",
    "\n",
    "# Get the top 30 most used symbols in the last 6 months\n",
    "top_symbols = (\n",
    "    recent_signals[\"symbol\"]\n",
    "    .value_counts()\n",
    "    .head(30)  # antes: .head(10)\n",
    "    .rename_axis(\"symbol\")\n",
    "    .reset_index(name=\"count\")\n",
    ")\n",
    "\n",
    "# Save new top\n",
    "top10_path = \"../data/clean/top_30_final_scored_symbols.csv\"\n",
    "top_symbols.to_csv(top10_path, index=False)\n",
    "\n",
    "print(\"Top 30 generated:\", len(top_symbols))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cb5d2a0-8e45-45b7-8694-5719a6f2b64f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load history per symbol\n",
    "symbol_stats_path = \"../data/clean/symbols_first_seen.csv\"\n",
    "symbol_stats = pd.read_csv(symbol_stats_path)\n",
    "\n",
    "# Convert date \n",
    "symbol_stats[\"last_signal_date\"] = pd.to_datetime(symbol_stats[\"last_signal_date\"], errors=\"coerce\")\n",
    "symbol_stats[\"symbol\"] = symbol_stats[\"symbol\"].str.upper()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2195ce8e-a6c1-4b2c-951d-66ee1c85ff17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure that top_symbols has well-defined columns\n",
    "top_symbols = (\n",
    "    recent_signals[\"symbol\"]\n",
    "    .value_counts()\n",
    "    .head(10)\n",
    "    .rename_axis(\"symbol\")  # convierte el índice en columna\n",
    "    .reset_index(name=\"count\")\n",
    ")\n",
    "\n",
    "# Create copy to enrich\n",
    "top_10_combined = top_symbols.copy()\n",
    "top_10_combined[\"symbol\"] = top_10_combined[\"symbol\"].str.upper()\n",
    "\n",
    "# Ensure symbol_stats is also uppercase\n",
    "symbol_stats[\"symbol\"] = symbol_stats[\"symbol\"].str.upper()\n",
    "\n",
    "# Merge to get the last signal date per symbol \n",
    "top_10_combined = top_10_combined.merge(\n",
    "    symbol_stats[[\"symbol\", \"last_signal_date\"]],\n",
    "    on=\"symbol\",\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "#Reorder columns\n",
    "top_10_combined = top_10_combined[[\"symbol\", \"count\", \"last_signal_date\"]]\n",
    "\n",
    "# Show results\n",
    "print(top_10_combined)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "764a8e03-e978-45a2-84d8-1257b3c06e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pybit.unified_trading import HTTP\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "session = HTTP()\n",
    "symbol = \"MYROUSDT\"\n",
    "\n",
    "# Download parameters\n",
    "interval = 60  # velas de 60 minutos\n",
    "end = int(datetime.now().timestamp()) * 1000\n",
    "start = int((datetime.now() - timedelta(days=30)).timestamp()) * 1000  # últimos 30 días\n",
    "\n",
    "# Obtain historical data (OHLCV)\n",
    "response = session.get_kline(\n",
    "    category=\"spot\",\n",
    "    symbol=symbol,\n",
    "    interval=str(interval),\n",
    "    start=start,\n",
    "    end=end\n",
    ")\n",
    "\n",
    "# Data access\n",
    "data = response[\"result\"][\"list\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f23e29a0-450e-4eef-addb-cb72c137adab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TP Matching – TODAS las señales desde 2024 (sin top N)\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "# Upload channel updates\n",
    "updates_path = \"../data/clean/telegram_updates_clean.csv\"\n",
    "updates_df = pd.read_csv(updates_path)\n",
    "updates_df[\"timestamp\"] = pd.to_datetime(updates_df[\"timestamp\"], utc=True, errors=\"coerce\")\n",
    "updates_df[\"symbol\"] = updates_df[\"symbol\"].str.upper()\n",
    "\n",
    "# Filter updates with a future date\n",
    "today = pd.Timestamp.utcnow()\n",
    "updates_df = updates_df[updates_df[\"timestamp\"] <= today]\n",
    "\n",
    "# Load full signals\n",
    "signals_path = \"../data/clean/telegram_signals_clean.csv\"\n",
    "df_signals = pd.read_csv(signals_path)\n",
    "df_signals[\"timestamp\"] = pd.to_datetime(df_signals[\"timestamp\"], utc=True, errors=\"coerce\")\n",
    "df_signals[\"symbol\"] = df_signals[\"symbol\"].str.upper()\n",
    "\n",
    "#Filter signals from 2024-01-01\n",
    "start_date = pd.Timestamp(2024, 1, 1, tz=\"UTC\")\n",
    "df_signals = df_signals[df_signals[\"timestamp\"] >= start_date].copy()\n",
    "\n",
    "# Initialize columns for results\n",
    "for tp in [\"tp_40\", \"tp_60\", \"tp_80\", \"tp_100\"]:\n",
    "    df_signals[f\"{tp}_result\"] = None\n",
    "\n",
    "#Tolerance to detect TP reached\n",
    "TOLERANCE = 0.0005  # 0.05%\n",
    "\n",
    "# Matching: compare each signal against subsequent updates\n",
    "for i, row in df_signals.iterrows():\n",
    "    symbol = row[\"symbol\"]\n",
    "    direction = row[\"direction\"]\n",
    "    signal_time = row[\"timestamp\"]\n",
    "\n",
    "    candidates = updates_df[\n",
    "        (updates_df[\"symbol\"] == symbol) &\n",
    "        (updates_df[\"direction\"] == direction) &\n",
    "        (updates_df[\"timestamp\"] > signal_time)\n",
    "    ]\n",
    "\n",
    "    for _, update in candidates.iterrows():\n",
    "        hit_price = update[\"hit_price\"]\n",
    "        hit_time = update[\"timestamp\"]\n",
    "\n",
    "        for tp in [\"tp_40\", \"tp_60\", \"tp_80\", \"tp_100\"]:\n",
    "            tp_val = row[tp]\n",
    "            if pd.isna(df_signals.at[i, f\"{tp}_result\"]):\n",
    "                if abs(hit_price - tp_val) / tp_val < TOLERANCE:\n",
    "                    df_signals.at[i, f\"{tp}_result\"] = hit_time\n",
    "\n",
    "# Save final file without filtering\n",
    "output_path = \"../telegram_signal_extractor/data/clean/signals_all_tp_results.csv\"\n",
    "df_signals.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"signals_all_tp_results.csv update {len(df_signals)} signals since 2024.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15bff46f-4275-4984-8e6d-7081d490c657",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visual verification of the results\n",
    "cols_to_show = [\n",
    "    \"symbol\", \"timestamp\", \"entry\", \"direction\",\n",
    "    \"tp_40\", \"tp_40_result\",\n",
    "    \"tp_60\", \"tp_60_result\",\n",
    "    \"tp_80\", \"tp_80_result\",\n",
    "    \"tp_100\", \"tp_100_result\"\n",
    "]\n",
    "\n",
    "df_signals_top10[cols_to_show].head(30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f6374c0-5c81-44b0-a643-2bdc10b8d29f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Route Configuration \n",
    "signals_path = \"../data/clean/telegram_signals_clean.csv\"\n",
    "prices_dir = \"../telegram_signal_extractor/data/bybit_prices\"\n",
    "output_path = \"../data/clean/signals_tp_evaluation.csv\"\n",
    "\n",
    "# Load signals \n",
    "df_signals = pd.read_csv(signals_path)\n",
    "df_signals[\"timestamp\"] = pd.to_datetime(df_signals[\"timestamp\"], utc=True, errors=\"coerce\")\n",
    "df_signals[\"symbol\"] = df_signals[\"symbol\"].str.upper()\n",
    "\n",
    "# Optional: filter from 2024\n",
    "df_signals = df_signals[df_signals[\"timestamp\"] >= pd.Timestamp(2024, 1, 1, tz=\"UTC\")].copy()\n",
    "\n",
    "#Load real prices from Bybit (1h candles per symbol) \n",
    "symbols = df_signals[\"symbol\"].unique()\n",
    "df_prices = {}\n",
    "\n",
    "for symbol in symbols:\n",
    "    price_file = os.path.join(prices_dir, f\"{symbol}.csv\")\n",
    "    if os.path.exists(price_file):\n",
    "        df = pd.read_csv(price_file)\n",
    "        df[\"timestamp\"] = pd.to_datetime(df[\"timestamp\"], utc=True, errors=\"coerce\")\n",
    "        df_prices[symbol] = df\n",
    "\n",
    "# Function to check if a TP was reached\n",
    "def check_tp_hit(price_df, signal_time, tp_value):\n",
    "    df_future = price_df[price_df[\"timestamp\"] > signal_time]\n",
    "    return (df_future[\"high\"] >= tp_value).any()\n",
    "\n",
    "#Principal evaluation\n",
    "results = []\n",
    "\n",
    "for _, row in df_signals.iterrows():\n",
    "    symbol = row[\"symbol\"]\n",
    "    signal_time = row[\"timestamp\"]\n",
    "    entry = row[\"entry\"]\n",
    "    direction = row[\"direction\"]\n",
    "\n",
    "    tps = {k: row[k] for k in [\"tp_40\", \"tp_60\", \"tp_80\", \"tp_100\"] if pd.notna(row[k])}\n",
    "\n",
    "    if symbol not in df_prices:\n",
    "        continue\n",
    "\n",
    "    price_data = df_prices[symbol]\n",
    "    result = {\n",
    "        \"symbol\": symbol,\n",
    "        \"timestamp\": signal_time,\n",
    "        \"entry\": entry,\n",
    "        \"direction\": direction\n",
    "    }\n",
    "\n",
    "    for tp_name, tp_val in tps.items():\n",
    "        result[tp_name + \"_hit\"] = check_tp_hit(price_data, signal_time, tp_val)\n",
    "\n",
    "    results.append(result)\n",
    "\n",
    "# Save results\n",
    "df_results = pd.DataFrame(results)\n",
    "df_results.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"Save file: {output_path}\")\n",
    "print(df_results.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9d19084-a563-4060-bac7-3e6f40e1ec09",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta, timezone\n",
    "from pybit.unified_trading import HTTP\n",
    "\n",
    "# Load cleaned signals\n",
    "signals_path = \"../data/clean/telegram_signals_clean.csv\"\n",
    "df = pd.read_csv(signals_path)\n",
    "df[\"timestamp\"] = pd.to_datetime(df[\"timestamp\"], utc=True, errors=\"coerce\")\n",
    "df[\"symbol\"] = df[\"symbol\"].str.upper()\n",
    "\n",
    "# Filter signals from 2024\n",
    "df = df[df[\"timestamp\"] >= pd.Timestamp(2024, 1, 1, tz=\"UTC\")].copy()\n",
    "\n",
    "# Get unique symbols\n",
    "symbols = df[\"symbol\"].unique()\n",
    "\n",
    "# Setup Bybit session\n",
    "session = HTTP()\n",
    "\n",
    "# Output directory\n",
    "output_dir = \"../data/bybit_prices_1m\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Configuration\n",
    "interval = \"1\"          # 1-minute candles\n",
    "limit = 1000            # candles per API call\n",
    "delay_between_calls = 1.5  # delay between requests in seconds\n",
    "\n",
    "# Download data per symbol\n",
    "for symbol in symbols:\n",
    "    try:\n",
    "        print(f\"Fetching data for: {symbol}\")\n",
    "\n",
    "        # Start 2 minutes before the first signal for safety\n",
    "        start_time = df[df[\"symbol\"] == symbol][\"timestamp\"].min() - timedelta(minutes=2)\n",
    "        end_time = datetime.now(timezone.utc)\n",
    "\n",
    "        all_data = []\n",
    "\n",
    "        while start_time < end_time:\n",
    "            start_ts = int(start_time.timestamp()) * 1000\n",
    "            end_ts = int((start_time + timedelta(minutes=limit)).timestamp()) * 1000\n",
    "\n",
    "            response = session.get_kline(\n",
    "                category=\"linear\",\n",
    "                symbol=symbol,\n",
    "                interval=interval,\n",
    "                start=start_ts,\n",
    "                end=end_ts\n",
    "            )\n",
    "\n",
    "            data = response.get(\"result\", {}).get(\"list\", [])\n",
    "            if not data:\n",
    "                break\n",
    "\n",
    "            df_chunk = pd.DataFrame(data, columns=[\n",
    "                \"timestamp\", \"open\", \"high\", \"low\", \"close\", \"volume\", \"turnover\"\n",
    "            ])\n",
    "            df_chunk[\"timestamp\"] = pd.to_datetime(df_chunk[\"timestamp\"].astype(int), unit=\"ms\", utc=True)\n",
    "            df_chunk[[\"open\", \"high\", \"low\", \"close\", \"volume\"]] = df_chunk[[\"open\", \"high\", \"low\", \"close\", \"volume\"]].astype(float)\n",
    "\n",
    "            all_data.append(df_chunk)\n",
    "\n",
    "            # Prepare for next batch\n",
    "            last_ts = df_chunk[\"timestamp\"].max()\n",
    "            last_ts = last_ts.tz_localize(\"UTC\") if last_ts.tzinfo is None else last_ts\n",
    "            start_time = last_ts + timedelta(minutes=1)\n",
    "\n",
    "            time.sleep(delay_between_calls)\n",
    "\n",
    "        if all_data:\n",
    "            full_df = pd.concat(all_data, ignore_index=True)\n",
    "            full_df.to_csv(os.path.join(output_dir, f\"{symbol}.csv\"), index=False)\n",
    "            print(f\"Saved {symbol}: {len(full_df)} rows\")\n",
    "        else:\n",
    "            print(f\"No data returned for {symbol}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error downloading {symbol}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41510fc1-48dd-44b0-8349-0008ba09d47e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "# Load top 10 symbols\n",
    "top10_path = \"../data/clean/top_10_final_scored_symbols.csv\"\n",
    "top_10 = pd.read_csv(top10_path)\n",
    "top_symbols = top_10[\"symbol\"].str.upper().unique()\n",
    "\n",
    "# Load clean signal data\n",
    "signals_path = \"../data/clean/telegram_signals_clean.csv\"\n",
    "df_signals = pd.read_csv(signals_path)\n",
    "df_signals[\"timestamp\"] = pd.to_datetime(df_signals[\"timestamp\"], utc=True, errors=\"coerce\")\n",
    "df_signals[\"symbol\"] = df_signals[\"symbol\"].str.upper()\n",
    "\n",
    "# Filter only top 10 symbols\n",
    "df_signals = df_signals[df_signals[\"symbol\"].isin(top_symbols)]\n",
    "\n",
    "# Load Bybit historical price data\n",
    "bybit_dir = \"..data/bybit_prices\"\n",
    "price_data = {}\n",
    "\n",
    "for symbol in top_symbols:\n",
    "    price_file = os.path.join(bybit_dir, f\"{symbol}.csv\")\n",
    "    if os.path.exists(price_file):\n",
    "        df_price = pd.read_csv(price_file)\n",
    "        df_price[\"timestamp\"] = pd.to_datetime(df_price[\"timestamp\"])\n",
    "        price_data[symbol] = df_price\n",
    "\n",
    "# Function to detect TP hit time \n",
    "def get_tp_hit_time(df_price, signal_time, tp_value, direction):\n",
    "    df_price[\"timestamp\"] = pd.to_datetime(df_price[\"timestamp\"], utc=True, errors=\"coerce\")\n",
    "    future_prices = df_price[df_price[\"timestamp\"] >= signal_time]\n",
    "    if future_prices.empty:\n",
    "        return \"No price data\"\n",
    "\n",
    "    if direction.lower() == \"long\":\n",
    "        hit = future_prices[future_prices[\"high\"] >= tp_value]\n",
    "    elif direction.lower() == \"short\":\n",
    "        hit = future_prices[future_prices[\"low\"] <= tp_value]\n",
    "    else:\n",
    "        return \"Invalid direction\"\n",
    "\n",
    "    if not hit.empty:\n",
    "        return hit.iloc[0][\"timestamp\"].strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    else:\n",
    "        return \"tp_40 not reached\"\n",
    "\n",
    "#Evaluate TP40 for each signal\n",
    "results = []\n",
    "for _, row in df_signals.iterrows():\n",
    "    symbol = row[\"symbol\"]\n",
    "    if symbol not in price_data:\n",
    "        continue\n",
    "\n",
    "    signal_time = row[\"timestamp\"]\n",
    "    entry = row[\"entry\"]\n",
    "    tp_40 = row[\"tp_40\"]\n",
    "    direction = row[\"direction\"]\n",
    "\n",
    "    result = {\n",
    "        \"symbol\": symbol,\n",
    "        \"timestamp\": signal_time,\n",
    "        \"entry\": entry,\n",
    "        \"tp_40\": tp_40,\n",
    "        \"direction\": direction\n",
    "    }\n",
    "\n",
    "    result[\"tp_40_result\"] = get_tp_hit_time(price_data[symbol], signal_time, tp_40, direction)\n",
    "    results.append(result)\n",
    "\n",
    "# --- 6. Save results to CSV ---\n",
    "df_result = pd.DataFrame(results)\n",
    "output_path = \"../data/clean/signals_tp40_time_v2.csv\"\n",
    "df_result.to_csv(output_path, index=False)\n",
    "print(f\" Saved TP40 evaluation to: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db627967-8123-4c53-8fd9-438b13af3f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load top 10 symbols \n",
    "top10_path = \"../data/clean/top_10_final_scored_symbols.csv\"\n",
    "top_10 = pd.read_csv(top10_path)\n",
    "top_symbols = top_10[\"symbol\"].str.upper().unique()\n",
    "\n",
    "# oad clean signal data\n",
    "signals_path = \"../data/clean/telegram_signals_clean.csv\"\n",
    "df_signals = pd.read_csv(signals_path)\n",
    "df_signals[\"timestamp\"] = pd.to_datetime(df_signals[\"timestamp\"], utc=True, errors=\"coerce\")\n",
    "df_signals[\"symbol\"] = df_signals[\"symbol\"].str.upper()\n",
    "\n",
    "# Filter only top 10 symbols\n",
    "df_signals = df_signals[df_signals[\"symbol\"].isin(top_symbols)]\n",
    "\n",
    "# Load Bybit historical price data\n",
    "bybit_dir = \"..data/bybit_prices\"\n",
    "price_data = {}\n",
    "\n",
    "for symbol in top_symbols:\n",
    "    price_file = os.path.join(bybit_dir, f\"{symbol}.csv\")\n",
    "    if os.path.exists(price_file):\n",
    "        df_price = pd.read_csv(price_file)\n",
    "        df_price[\"timestamp\"] = pd.to_datetime(df_price[\"timestamp\"], utc=True, errors=\"coerce\")\n",
    "        price_data[symbol] = df_price\n",
    "\n",
    "# Function to detect TP hit time ---\n",
    "def get_tp_hit_time(df_price, signal_time, tp_value, direction):\n",
    "    future_prices = df_price[df_price[\"timestamp\"] >= signal_time]\n",
    "    if future_prices.empty:\n",
    "        return \"No price data\"\n",
    "\n",
    "    if direction.lower() == \"long\":\n",
    "        hit = future_prices[future_prices[\"high\"] >= tp_value]\n",
    "    elif direction.lower() == \"short\":\n",
    "        hit = future_prices[future_prices[\"low\"] <= tp_value]\n",
    "    else:\n",
    "        return \"Invalid direction\"\n",
    "\n",
    "    if not hit.empty:\n",
    "        return hit.iloc[0][\"timestamp\"].strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    else:\n",
    "        return \"TP not reached\"\n",
    "\n",
    "# Evaluate all TP levels for each signal ---\n",
    "results = []\n",
    "for _, row in df_signals.iterrows():\n",
    "    symbol = row[\"symbol\"]\n",
    "    if symbol not in price_data:\n",
    "        continue\n",
    "\n",
    "    signal_time = row[\"timestamp\"]\n",
    "    entry = row[\"entry\"]\n",
    "    direction = row[\"direction\"]\n",
    "\n",
    "    result = {\n",
    "        \"symbol\": symbol,\n",
    "        \"timestamp\": signal_time,\n",
    "        \"entry\": entry,\n",
    "        \"direction\": direction,\n",
    "        \"tp_40\": row[\"tp_40\"],\n",
    "        \"tp_60\": row[\"tp_60\"],\n",
    "        \"tp_80\": row[\"tp_80\"],\n",
    "        \"tp_100\": row[\"tp_100\"],\n",
    "    }\n",
    "\n",
    "    price_df = price_data[symbol]\n",
    "\n",
    "    result[\"tp_40_result\"] = get_tp_hit_time(price_df, signal_time, row[\"tp_40\"], direction)\n",
    "    result[\"tp_60_result\"] = get_tp_hit_time(price_df, signal_time, row[\"tp_60\"], direction)\n",
    "    result[\"tp_80_result\"] = get_tp_hit_time(price_df, signal_time, row[\"tp_80\"], direction)\n",
    "    result[\"tp_100_result\"] = get_tp_hit_time(price_df, signal_time, row[\"tp_100\"], direction)\n",
    "\n",
    "    results.append(result)\n",
    "\n",
    "# Save results to CSV \n",
    "df_result = pd.DataFrame(results)\n",
    "output_path = \"../data/clean/signals_all_tp_results.csv\"\n",
    "df_result.to_csv(output_path, index=False)\n",
    "print(f\"Saved full TP evaluation to: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7508f7f3-2092-485a-9482-a64a7732829e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Local path to the updates file\n",
    "updates_path = \"../data/clean/telegram_updates_clean.csv\"\n",
    "updates_df = pd.read_csv(updates_path)\n",
    "\n",
    "#Convert dates\n",
    "df_signals[\"timestamp\"] = pd.to_datetime(df_signals[\"timestamp\"], utc=True, errors=\"coerce\")\n",
    "updates_df[\"timestamp\"] = pd.to_datetime(updates_df[\"timestamp\"], utc=True, errors=\"coerce\")\n",
    "\n",
    "#Initialize empty columns\n",
    "for tp in [\"tp_40\", \"tp_60\", \"tp_80\", \"tp_100\"]:\n",
    "    df_signals[f\"{tp}_result\"] = None\n",
    "\n",
    "#Define tolerance\n",
    "TOLERANCE = 0.001\n",
    "\n",
    "# Matching\n",
    "for i, row in df_signals.iterrows():\n",
    "    symbol = row[\"symbol\"]\n",
    "    direction = row[\"direction\"]\n",
    "    signal_time = row[\"timestamp\"]\n",
    "\n",
    "    candidates = updates_df[\n",
    "        (updates_df[\"symbol\"] == symbol) &\n",
    "        (updates_df[\"direction\"] == direction) &\n",
    "        (updates_df[\"timestamp\"] > signal_time)\n",
    "    ]\n",
    "\n",
    "    for _, update in candidates.iterrows():\n",
    "        hit_price = update[\"hit_price\"]\n",
    "        ts = update[\"timestamp\"]\n",
    "\n",
    "        for tp in [\"tp_40\", \"tp_60\", \"tp_80\", \"tp_100\"]:\n",
    "            target = row[tp]\n",
    "            if df_signals.at[i, f\"{tp}_result\"] is None:\n",
    "                if abs(hit_price - target) / target < TOLERANCE:\n",
    "                    df_signals.at[i, f\"{tp}_result\"] = ts\n",
    "\n",
    "# Save updated file\n",
    "output_path = \"../data/clean/signals_all_tp_results.csv\"\n",
    "df_signals.to_csv(output_path, index=False)\n",
    "\n",
    "print(\"File signals_all_tp_results.csv updated with actual results .\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (final_proyect_env)",
   "language": "python",
   "name": "final_proyect_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
